---
layout: post
title: Understanding Variational Lower Bound
---

Variantional Bayesian (VB) methods are a popular family of techniques (along with Generative Advesarial Networks (GANs) [1] and Fully visible belief networks (FVBNs) [2]) 
in statistical machine learning, in particular, for training generative models. VB methods allow us to cast the statistical inference problems into optimization problems
which can be solved by latest optimization algorithms. The optimization objective known as Variational Lower Bound, is proposed in Varionational Autoencoders (VAE) [3] is 
one of the simplest form of VB methods. This goal of this post is to learn about this Variational Lower Bound.

#References

[1] Ian Goodfellow et al, NIPS 2014.
[2] (Frey et al., 1996; Frey, 1998) 
[3] Varionational Autoencoders

